{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing multiple models\n",
    "in this notebook, multiple models will be made with the png's of the Lactic acid experiment\n",
    "(mostly bad results because of not enough data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "from transform_functions import get_data_rf, get_data\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 \n",
    "simple RF classifier, no balance found/not found, train all data at once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/media/sf_SF/Stage2021/test_ML/\" #test directory\n",
    "\n",
    "#get data\n",
    "X_train,y_train = get_data(PATH+\"ML_train/\")\n",
    "X_test, y_test = get_data(PATH+\"ML_test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.84      1.00      0.91        42\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.42      0.50      0.46        50\n",
      "weighted avg       0.71      0.84      0.77        50\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "[[ 0  8]\n",
      " [ 0 42]]\n",
      "\n",
      "accuracy\n",
      "84.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(max_depth = 2, random_state = 0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nconfusion matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"\\naccuracy\")\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Png's found and not found are balanced in the train (2/3) and test set (1/3).\n",
    "The train data is split up in multiple sets, the model grows with warm start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "26\n",
      "nf_test :  9 f_test 41\n",
      "nf_train :  9 f_train 83\n",
      "all_test :  50\n",
      "all_train :  100\n",
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "[1 1 1 1 1 1 1 0 1 1]\n",
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "[1 1 1 1 0 0 0 0]\n",
      "----------\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "[1 1 1 1 0 0 0 0]\n",
      "----------\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "[1 1 1 1 0 0 0 0]\n",
      "----------\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#select project map where found + nf directories are\n",
    "PROJECT = \"/media/sf_SF/Stage2021/test_ML/\"\n",
    "\n",
    "founds = os.listdir(PROJECT+\"found/\")\n",
    "length_fo = len(founds)\n",
    "\n",
    "not_founds = os.listdir(PROJECT+\"not_found/\")\n",
    "length_nf = len(not_founds)\n",
    "\n",
    "print(length_fo)\n",
    "print(length_nf)\n",
    "\n",
    "#divide data\n",
    "#1/3 of founds = test data, 2/3 of founds = train data\n",
    "test_fo = (sample(founds,round(length_fo/3)))\n",
    "train_fo = list(set(founds) - set(test_fo))\n",
    "\n",
    "#1/3 of not founds = test data, 2/3 of not founds = train data\n",
    "test_nf = (sample(not_founds,round(length_nf/3)))\n",
    "train_nf = list(set(not_founds) - set(test_nf))\n",
    "\n",
    "#divide into two lists\n",
    "all_test = test_fo + test_nf\n",
    "all_train = train_fo + train_nf\n",
    "\n",
    "print(\"nf_test : \", len(test_nf), \"f_test\", len(test_fo))\n",
    "print(\"nf_train : \", len(test_nf), \"f_train\", len(train_fo))\n",
    "\n",
    "print(\"all_test : \", len(all_test))\n",
    "print(\"all_train : \", len(all_train))\n",
    "\n",
    "#select test data \n",
    "sel_test = (sample(all_test, 10))\n",
    "X_test, y_test = get_data_rf(PROJECT, sel_test)\n",
    "print(X_test)\n",
    "print(y_test)\n",
    "\n",
    "#make classifier\n",
    "cls = RandomForestClassifier(n_estimators=1000, warm_start=True, max_features=2)\n",
    "\n",
    "#make loop to create different train data sets (let the model grow with warm start, goes faster for big data)\n",
    "for j in range(3): #now 2 times loop, bcs not enough data \n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "    #make subgroup to train the data \n",
    "    sel_train_fo = sample(train_fo,4)\n",
    "    sel_train_nf = sample(train_nf,4)\n",
    "    # print(sel_train_fo)\n",
    "    # print(sel_train_nf)\n",
    "    sel_train = sel_train_fo + sel_train_nf\n",
    "    train_nf = list(set(train_nf) - set(sel_train_nf))\n",
    "    train_fo = list(set(train_fo) - set(sel_train_fo))\n",
    "    X_train,y_train = get_data_rf(PROJECT, sel_train)\n",
    "    print(X_train)\n",
    "    print(y_train)   \n",
    "    cls.n_estimators += 10 \n",
    "    cls.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"-\"*10)\n",
    "    #Hoe belangrijk is elke feature voor het model (0.22 en 0.15 zullen dan degene zijn die gebruikt worden aangezien je slecht 2 features gebruikt hier)\n",
    "    print(cls.feature_importances_)\n",
    "    #Vb van 1 boom\n",
    "    #plt.figure(figsize=(80,80))\n",
    "    #_ = tree.plot_tree(cls.estimators_[0], filled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*feature importance is steeds nul bij mij?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40         1\n",
      "           1       1.00      0.67      0.80         9\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.62      0.83      0.60        10\n",
      "weighted avg       0.93      0.70      0.76        10\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "[[1 0]\n",
      " [3 6]]\n",
      "\n",
      "accuracy\n",
      "70.0\n"
     ]
    }
   ],
   "source": [
    "# Test Random Forest Classifier\n",
    "y_pred = cls.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nconfusion matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"\\naccuracy\")\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*waarom een accuracy van slechts 40 als het eerste model dubbel zoveel is?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "the train data is not split up here \n",
    "(max_features bepaalt hoeveel features gebruikt mogen worden per split per boom. Zo bekom je de \"randomness\" in de random forest trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "26\n",
      "nf_test :  9 f_test 41\n",
      "nf_train :  9 f_train 83\n",
      "all_test :  50\n",
      "all_train :  100\n",
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=2, n_estimators=1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select project map where found + nf directories are\n",
    "PROJECT = \"/media/sf_SF/Stage2021/test_ML/\"\n",
    "\n",
    "founds = os.listdir(PROJECT+\"found/\")\n",
    "length_fo = len(founds)\n",
    "\n",
    "not_founds = os.listdir(PROJECT+\"not_found/\")\n",
    "length_nf = len(not_founds)\n",
    "\n",
    "print(length_fo)\n",
    "print(length_nf)\n",
    "\n",
    "#divide data\n",
    "#1/3 of founds = test data, 2/3 of founds = train data\n",
    "test_fo = (sample(founds,round(length_fo/3)))\n",
    "train_fo = list(set(founds) - set(test_fo))\n",
    "\n",
    "#1/3 of not founds = test data, 2/3 of not founds = train data\n",
    "test_nf = (sample(not_founds,round(length_nf/3)))\n",
    "train_nf = list(set(not_founds) - set(test_nf))\n",
    "\n",
    "#divide into two lists\n",
    "all_test = test_fo + test_nf\n",
    "all_train = train_fo + train_nf\n",
    "\n",
    "print(\"nf_test : \", len(test_nf), \"f_test\", len(test_fo))\n",
    "print(\"nf_train : \", len(test_nf), \"f_train\", len(train_fo))\n",
    "\n",
    "print(\"all_test : \", len(all_test))\n",
    "print(\"all_train : \", len(all_train))\n",
    "\n",
    "#get X_train, y_train... \n",
    "X_test, y_test = get_data_rf(PROJECT, all_test)\n",
    "X_train,y_train = get_data_rf(PROJECT, all_train)\n",
    "print(X_test)\n",
    "print(y_test)\n",
    "\n",
    "#make classifier\n",
    "cls2 = RandomForestClassifier(n_estimators=1000, max_features=2)\n",
    "cls2.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.82      1.00      0.90        41\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.41      0.50      0.45        50\n",
      "weighted avg       0.67      0.82      0.74        50\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "[[ 0  9]\n",
      " [ 0 41]]\n",
      "\n",
      "accuracy\n",
      "82.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Test Random Forest Classifier\n",
    "y_pred = cls2.predict(X_test)\n",
    "print(\"\\nprediction\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nconfusion matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"\\naccuracy\")\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.67         8\n",
      "           1       0.93      0.95      0.94        42\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.82      0.79      0.80        50\n",
      "weighted avg       0.90      0.90      0.90        50\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "[[ 5  3]\n",
      " [ 2 40]]\n",
      "\n",
      "accuracy\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "PROJECT = \"/media/sf_SF/Stage2021/test_ML/\"\n",
    "\n",
    "X_train,y_train = get_data(PROJECT+\"ML_train/\")\n",
    "X_test, y_test = get_data(PROJECT+\"ML_test/\")\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=20, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nconfusion matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"\\naccuracy\")\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "Kan je boom verbeteren tijdens trainen. Hier moet je dan beetje spelen met de complexity om eventueel betere resultaten te krijgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62         8\n",
      "           1       0.91      0.98      0.94        42\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.86      0.74      0.78        50\n",
      "weighted avg       0.89      0.90      0.89        50\n",
      "\n",
      "[[ 4  4]\n",
      " [ 1 41]]\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "# Bagging met logistic regression\n",
    "PROJECT = \"/media/sf_SF/Stage2021/test_ML/\"\n",
    "\n",
    "X_train,y_train = get_data(PROJECT+\"ML_train/\")\n",
    "X_test, y_test = get_data(PROJECT+\"ML_test/\")\n",
    "\n",
    "number_of_estimators = 100\n",
    "complexity = 10\n",
    "cart = LogisticRegression(C=complexity,solver='liblinear')\n",
    "\n",
    "\n",
    "lregbagging = BaggingClassifier(base_estimator=cart, n_estimators=number_of_estimators)\n",
    "lregbagging.fit(X_train,y_train)\n",
    "y_pred = lregbagging.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "Andere manier naast bagging die ook rekening houd met resultaten van vorige training, hier spelen met learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.95      0.98      0.96        42\n",
      "\n",
      "    accuracy                           0.94        50\n",
      "   macro avg       0.91      0.86      0.88        50\n",
      "weighted avg       0.94      0.94      0.94        50\n",
      "\n",
      "[[ 6  2]\n",
      " [ 1 41]]\n",
      "94.0\n"
     ]
    }
   ],
   "source": [
    "# Adaboost\n",
    "PROJECT = \"/media/sf_SF/Stage2021/test_ML/\"\n",
    "\n",
    "X_train,y_train = get_data(PROJECT+\"ML_train/\")\n",
    "X_test, y_test = get_data(PROJECT+\"ML_test/\")\n",
    "\n",
    "clf_adaboost = AdaBoostClassifier(n_estimators=150,learning_rate=0.9)\n",
    "clf_adaboost.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf_adaboost.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "Geen boom, gewoon simpele logistic regression. Er onder nog een paar andere boosting technieken. XDGboost wordt momenteel redelijk vaak gebruikt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62         8\n",
      "           1       0.91      0.98      0.94        42\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.86      0.74      0.78        50\n",
      "weighted avg       0.89      0.90      0.89        50\n",
      "\n",
      "[[ 4  4]\n",
      " [ 1 41]]\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "# Adaboost met logistic regression classifier\n",
    "PROJECT = \"/media/sf_SF/Stage2021/test_ML/\"\n",
    "\n",
    "X_train,y_train = get_data(PROJECT+\"ML_train/\")\n",
    "X_test, y_test = get_data(PROJECT+\"ML_test/\")\n",
    "\n",
    "cart = LogisticRegression(C=complexity,solver='liblinear')\n",
    "logreg_adaboost = AdaBoostClassifier(base_estimator=cart,n_estimators=150,learning_rate=0.9) \n",
    "logreg_adaboost.fit(X_train,y_train)\n",
    "\n",
    "y_pred = logreg_adaboost.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.38      0.50         8\n",
      "           1       0.89      0.98      0.93        42\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.82      0.68      0.72        50\n",
      "weighted avg       0.87      0.88      0.86        50\n",
      "\n",
      "[[ 3  5]\n",
      " [ 1 41]]\n",
      "88.0\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting\n",
    "PROJECT = \"/media/sf_SF/Stage2021/test_ML/\"\n",
    "\n",
    "X_train,y_train = get_data(PROJECT+\"ML_train/\")\n",
    "X_test, y_test = get_data(PROJECT+\"ML_test/\")\n",
    "\n",
    "clf_gradientboost = GradientBoostingClassifier(n_estimators=150,learning_rate=0.8)\n",
    "clf_gradientboost.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = clf_gradientboost.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
