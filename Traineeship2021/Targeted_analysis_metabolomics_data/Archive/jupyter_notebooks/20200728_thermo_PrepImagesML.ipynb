{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for targeted metabolomics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare images for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.codespeedy.com/prepare-your-own-data-set-for-image-classification-python/\n",
    "## Prepare your own data set for image classification in Machine learning Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is large amount of open source data sets available on the Internet for Machine Learning, but while managing your own project you may require your own data set. Today, let’s discuss how can we prepare our own data set for Image Classification.\n",
    "Collect Image data\n",
    "\n",
    "The first and foremost task is to collect data (images). One can use camera for collecting images or download from Google Images (copyright images needs permission). There are many browser plugins for downloading images in bulk from Google Images. Suppose you want to classify cars to bikes. Download images of cars in one folder and bikes in another folder.\n",
    "Process the Data\n",
    "\n",
    "The downloaded images may be of varying pixel size but for training the model we will require images of same sizes. So let’s resize the images using simple Python code. We will be using built-in library PIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "def resize_multiple_images(src_path, dst_path):\n",
    "    # Here src_path is the location where images are saved.\n",
    "    for filename in os.listdir(src_path):\n",
    "        try:\n",
    "            img=Image.open(src_path+filename)\n",
    "            new_img = img.resize((64,64))\n",
    "            if not os.path.exists(dst_path):\n",
    "                os.makedirs(dst_path)\n",
    "            new_img.save(dst_path+filename)\n",
    "            print('Resized and saved {} successfully.'.format(filename))\n",
    "        except:\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"C:/Users/Marilyn/Desktop/imagesNF/\" #<Enter the source path>\n",
    "dst_path = \"C:/Users/Marilyn/Desktop/image_resizeNF/\" #<Enter the destination path>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized and saved contour plot 200929s001_STD-STD073.png successfully.\n",
      "Resized and saved contour plot 200929s003_STD-STD073.png successfully.\n",
      "Resized and saved contour plot 200929s007_STD-STD073.png successfully.\n",
      "Resized and saved contour plot 200929s017_STD-STD073.png successfully.\n",
      "Resized and saved contour plot 200929s037_STD-STD073.png successfully.\n",
      "Resized and saved contour plot 200929s047_STD-STD073.png successfully.\n",
      "Resized and saved contour plot 200929s049_STD-STD073.png successfully.\n",
      "Resized and saved contour plot 200929s050_STD-STD073.png successfully.\n",
      "Resized and saved contour plot 200929s051_STD-STD073.png successfully.\n",
      "Resized and saved contour plot 200929s052_STD-STD073.png successfully.\n"
     ]
    }
   ],
   "source": [
    "resize_multiple_images(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img=Image.open(\"C:/Users/Marilyn/Desktop/imagesF/contour plot 200929s001_STD-STD073.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images should have small size so that the number of features is not large enough while feeding the images into a Neural Network. For example, a colored image is 600X800 large, then the Neural Network need to handle 600*800*3 = 1,440,000 parameters, which is quite large. On the other hand any colored image of 64X64 size needs only 64*64*3 = 12,288 parameters, which is fairly low and will be computationally efficient. Now since we have resized the images, we need to rename the files so as to properly label the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_multiple_files(path,obj):\n",
    "\n",
    "    i=0\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        try:\n",
    "            f,extension = os.path.splitext(path+filename)\n",
    "            src=path+filename\n",
    "            dst=path+filename+obj+str(i)+extension\n",
    "            os.rename(src,dst)\n",
    "            i+=1\n",
    "            print('Rename successful.')\n",
    "        except:\n",
    "            i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n",
      "Rename successful.\n"
     ]
    }
   ],
   "source": [
    "path= \"C:/Users/Marilyn/Desktop/image_resizeF/\" #<Enter the path of objects to be renamed>\n",
    "obj= \"FOUND\"#<Enter the prefix to be added to each file. For ex. car, bike, cat, dog, etc.>\n",
    "rename_multiple_files(path,obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, we have processed our data. Merge the content of ‘car’ and ‘bikes’ folder and name it ‘train set’. Pull out some images of cars and some of bikes from the ‘train set’ folder and put it in a new folder ‘test set’. Now we have to import it into our python code so that the colorful image can be represented in numbers to be able to apply Image Classification Algorithms.\n",
    "\n",
    "Import Images in form of array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def get_data(path):\n",
    "    all_images_as_array=[]\n",
    "    label=[]\n",
    "    for filename in os.listdir(path):\n",
    "        try:\n",
    "            if re.match(r'FOUND',filename): #<Edit obj here>\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "            img=Image.open(path + filename)\n",
    "            np_array = np.asarray(img)\n",
    "            l,b,c = np_array.shape    \n",
    "            np_array = np_array.reshape(l*b*c,)   \n",
    "            all_images_as_array.append(np_array)\n",
    "        except:\n",
    "            print(filename) #if error with 2dim, print\n",
    "            continue\n",
    "\n",
    "    return np.array(all_images_as_array), np.array(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_set = \"C:/Users/Marilyn/Desktop/train/\" #<Enter the location of train set>\n",
    "path_to_test_set = \"C:/Users/Marilyn/Desktop/test/\" #<Enter the location of test set>\n",
    "X_train,y_train = get_data(path_to_train_set)\n",
    "X_test, y_test = get_data(path_to_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! You made it. Your image classification data set is ready to be fed to the neural network model. Feel free to comment below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train set :  [[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "y_train set :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "X_test set :  [[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "y_test set :  [1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('X_train set : ',X_train) #trainingsdata\n",
    "print('y_train set : ',y_train) #vector met labels 1=FOUND, 0=NF\n",
    "print('X_test set : ',X_test)\n",
    "print('y_test set : ',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img=Image.open(\"C:/Users/Marilyn/Desktop/test/FOUND0.png\")\n",
    "#np_array = np.asarray(img)\n",
    "#print(np_array)\n",
    "#np_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 12288)\n",
      "(59,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 12288)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model SVM\n",
    "#https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-download-auto-examples-classification-plot-digits-classification-py\n",
    "#probeer kernel rbf (pole cordin ipv gewone die lijn probeert te trekken) gezien ik sphere zoek\n",
    "#Radial Basis Function (RBF) kernel SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Now predict the value of the digit on the second half:\n",
    "predicted = classifier.predict(X_test)\n",
    "print(predicted)\n",
    "#NOK, alles denkt FOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test set :  [1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#real answer test label\n",
    "print('y_test set : ',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.codespeedy.com/naive-bayes-algorithm-in-python/\n",
    "# model Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nv = GaussianNB() # create a classifier\n",
    "nv.fit(X_train,y_train) # fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = nv.predict(X_test) # store the prediction data\n",
    "accuracy_score(y_test,y_pred) # calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "#ok, dus 1 fout van NF -> denk FOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test set :  [1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#real answer test label\n",
    "print('y_test set : ',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uitlezen pd (read.csv(/t) in loop, matrix 'flatten' als 1 array, alle arays in lijst, erna np.array(List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp classifier, \n",
    "#hiddel layer v [100, 1] = 1 laag van honderd 100 iddenh, [100, 100] = 2 lagen van honderd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100, ), activation='relu').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395],\n",
       "       [0.51567605, 0.48432395]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sololearn, ev to add:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print(\"precision:\", precision_score(y_test, predicted))\n",
    "print(\"recall:\", recall_score(y_test, predicted))\n",
    "print(\"f1 score:\", f1_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y, y_pred))\n",
    "#Scikit-learn reverses the confusion matrix to show the negative counts first!\n",
    "# Output:\n",
    "# actual as rows\n",
    "#  [[TN  FP]\n",
    "#  [FN TP]]\n",
    "# 0 = neg, 1 = pos reason reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "#By default the training set is 75% of the data and the test set is the remaining 25% of the data.\n",
    "print(\"whole dataset:\", X.shape, y.shape)\n",
    "print(\"training set:\", X_train.shape, y_train.shape)\n",
    "print(\"test set:\", X_test.shape, y_test.shape)\n",
    "train_test_split(X, y, train_size=0.6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"precision:\", precision_score(y_test, y_pred))\n",
    "print(\"recall:\", recall_score(y_test, y_pred))\n",
    "print(\"f1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=27)\n",
    "#alias seed, always same plit instead of random result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_score = recall_score\n",
    "print(sensitivity_score(y_test, y_pred)) \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "print(precision_recall_fscore_support(y, y_pred))\n",
    "def specificity_score(y_true, y_pred):\n",
    "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred)\n",
    "    return r[0]\n",
    "print(specificity_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.predict_proba(X_test)\n",
    " model.predict_proba(X_test)[:, 1]\n",
    " y_pred = model.predict_proba(X_test)[:, 1] > 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('1 - specificity')\n",
    "plt.ylabel('sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(roc_auc_score(y_test, y_pred_proba[:,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
