{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e538107",
   "metadata": {},
   "source": [
    "CNN 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207cabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.io import imread, imshow\n",
    "from skimage import data, color, io, filters, morphology,transform, exposure, feature, util\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "#importeer Tensorflow namespaces\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#K.set_image_dim_ordering('tf')\n",
    "\n",
    "###### Voor Tensorflow-GPU ########\n",
    "\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e96ae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "############Adjustments##############\n",
    "\n",
    "#options\n",
    "PATH_DI06C001 = '/media/sf_SF/Stage2021/targetedQE/' \n",
    "\n",
    "## Adjustments\n",
    "path = PATH_DI06C001\n",
    "\n",
    "filename_Y_labels = 'total_y_matrix_with_binary_label.txt'\n",
    "\n",
    "########################\n",
    "\n",
    "\n",
    "\n",
    "# load libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#set paths\n",
    "path_data_in = path + 'data/input/' + 'MachineLearning/'\n",
    "path_data_out = path + 'data/output/' + 'MachineLearning/'\n",
    "path_data_X = path_data_in + 'Xarrays_bw/' #png's\n",
    "path_data_y = path_data_in + 'Yarrays/' #labels\n",
    "\n",
    "\n",
    "\n",
    "## Y\n",
    "#load all Y labels together\n",
    "filename = path_data_y + filename_Y_labels\n",
    "# print(filename)\n",
    "\n",
    "y = pd.read_csv(filename, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "## X\n",
    "#list all X files and devide in train OR test folder\n",
    "filenames_X_train = []\n",
    "filenames_X_test = []\n",
    "directory_list = os.listdir(path_data_X)\n",
    "# print(directory_list)\n",
    "\n",
    "#random order list with filenames\n",
    "random.shuffle(directory_list)\n",
    "\n",
    "os.chdir(path_data_X)\n",
    "\n",
    "i = 0\n",
    "for filename in directory_list:\n",
    "    #print (filename) #all files, folders\n",
    "    #print (i)\n",
    "    if \".png\" in filename :\n",
    "        #print (filename)\n",
    "        if i % 3 == 0: \n",
    "            #1/3th of data is test set, rest in train\n",
    "            #print(i)\n",
    "            filenames_X_test.append(path_data_X + filename)\n",
    "        else:\n",
    "            filenames_X_train.append(path_data_X + filename)\n",
    "        i = i + 1\n",
    "        \n",
    " #check ok? 70-30 devide train - test? ok     \n",
    "print(len(filenames_X_train))\n",
    "print(len(filenames_X_test))\n",
    "\n",
    "\n",
    "## load X data + Merge per train/test X's with Y to S1\n",
    "#keep only non unique values\n",
    "\n",
    "\n",
    "def load_X_if_matched_in_y(filenames_list, y):\n",
    "    all_images_as_array=[]\n",
    "    label=[]    \n",
    "    # match = 0\n",
    "    # no_match = 0\n",
    "    for filename in filenames_list:\n",
    "        #print(filename)\n",
    "        #filename = filenames_X_train[3]\n",
    "        filename_wopath = filename.split('Xarrays_bw/')[1]\n",
    "        #filename_wopath = filename_wopath[:-4] #wo .png todo, see same x/y !!!\n",
    "        #filename_wobw = filename_wopath.split('_bw')[0]+\".png\"\n",
    "        #print(filename_wopath)\n",
    "    \n",
    "        matching_y = y[y.png==filename_wopath]\n",
    "        #print(matching_y)\n",
    "        if len(matching_y) == 1:\n",
    "            label.append(matching_y.iloc[0,2]) #1st elem contains string NF/FOUND\n",
    "            \n",
    "            #load figure correctly as array [[], [], []]]\n",
    "            img=Image.open(filename)\n",
    "            np_array = np.asarray(img)\n",
    "            #print(np_array.shape)\n",
    "            \n",
    "            l,b = np_array.shape    \n",
    "            np_array = np_array.reshape(l*b,)   \n",
    "            all_images_as_array.append(np_array)\n",
    "            # match = match + 1\n",
    "            \n",
    "        if len(matching_y) != 1:\n",
    "            # print(\"no or multiple match(es) in y found for: \" + filename)\n",
    "            # no_match = no_match + 1\n",
    "            continue\n",
    "\n",
    "    return np.array(all_images_as_array), np.array(label)\n",
    "    \n",
    "\n",
    "#if re.match(filename_wopath, y.Name[0]): #todo search in volled colom, ev niet via regress want wo .png moet volled zelfde\n",
    "        \n",
    "\n",
    "\n",
    "X_train,y_train = load_X_if_matched_in_y(filenames_X_train, y)\n",
    "X_test, y_test = load_X_if_matched_in_y(filenames_X_test, y)\n",
    "\n",
    "\n",
    "print(X_train)\n",
    "print(len(y_train))\n",
    "print(X_test)\n",
    "print(len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393deaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,64, 64,1)\n",
    "X_test = X_test.reshape(-1,64, 64,1)\n",
    "\n",
    "# Normalisatie\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3aa9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reshaping\n",
    "X_train = X_train.reshape(-1,64, 64,1)\n",
    "X_test = X_test.reshape(-1,64, 64,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6   \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "\n",
    "imshow(X_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30cfddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Normalisatie\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d212c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6   \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "\n",
    "imshow(X_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4eb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toon afbeelding\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "index = 6   \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "\n",
    "imshow(X_train[index])\n",
    "#imshow(X_test[index].reshape((64,64)),cmap='gray')\n",
    "# imshow(X_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(X_test[10].reshape((64,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2891c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network parameters\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "batch_size = 32 # \n",
    "epochs = 150 # \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "num_classes = 2\n",
    "img_rows, img_cols = 64, 64\n",
    "input_shape = (img_rows, img_cols,1)\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Conv2D(32, kernel_size=(9, 9), activation='relu',input_shape=input_shape)) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(0.3)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "model.add(BatchNormalization())\n",
    "#-----------------------------------------------\n",
    "model.add(Conv2D(32, (3, 3), activation='relu')) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(0.3)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "model.add(BatchNormalization())\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(50, activation='relu')) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(0.2)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dense(num_classes, activation='relu')) # relu / softmax / sigmoid\n",
    "\n",
    "#model.compile(loss=\"categorical_crossentropy\",\n",
    "#              optimizer='adam',\n",
    "#              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148fe4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#              optimizer=keras.optimizers.Adadelta(),\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06216351",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a352e4ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e268ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuray \n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# Loss \n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38061865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performantie op de test data\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print('\\n')\n",
    "print('accuracy score:', accuracy_score(y_test, y_pred) * 100) \n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuray \n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model and test accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# Loss \n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3800902c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
