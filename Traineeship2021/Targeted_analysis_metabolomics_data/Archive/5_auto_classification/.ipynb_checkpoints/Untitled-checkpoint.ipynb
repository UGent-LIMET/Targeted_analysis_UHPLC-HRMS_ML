{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b9eed1",
   "metadata": {},
   "source": [
    "get test/train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02572580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3406\n",
      "1704\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 10 15:26:44 2021\n",
    "\n",
    "@author: Marilyn\n",
    "\"\"\"\n",
    "#info voor loes: structuur R pipeline is\n",
    "#> Data -> Input, Output, Tests\n",
    "#> R_scipts\n",
    "#> py_scripts\n",
    "#onder data/input/EXPEMENT staat alles dat bij 1 proef hoort, vb map 'TEST_targetedQE' (zie inhoud onedrive)\n",
    "#indiv data voor aanmaak x, y zit in map input/EXP/ in verschillende submappen vb bio (maar niet erg)\n",
    "#voor uiteindelijke database (alle x,y), als in 1 experiment map zitten met 2 subfolders: Xarrays, Yarrays\n",
    "#in testvoorbeeld zal ik zelfde folder gebruiken voor gemak\n",
    "\n",
    "\n",
    "\n",
    "############Adjustments##############\n",
    "\n",
    "#options\n",
    "PATH_DI06C001 = '/media/sf_SF/Stage2021/targetedQE/' \n",
    "\n",
    "## Adjustments\n",
    "EXPERIMENT = 'EXPERIMENT'\n",
    "\n",
    "path = PATH_DI06C001\n",
    "\n",
    "filename_Y_labels = 'total_y_matrix_with_label.txt'\n",
    "\n",
    "########################\n",
    "\n",
    "\n",
    "\n",
    "# load libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#set paths\n",
    "path_data_in = path + 'data/input/' + EXPERIMENT + '/'\n",
    "path_data_out = path + 'data/output/' + EXPERIMENT + '/'\n",
    "path_data_X = path_data_in + 'Xarrays/' #png's\n",
    "path_data_y = path_data_in + 'Yarrays/' #labels\n",
    "\n",
    "\n",
    "\n",
    "## Y\n",
    "#load all Y labels together\n",
    "filename = path_data_y + filename_Y_labels\n",
    "# print(filename)\n",
    "\n",
    "y = pd.read_csv(filename, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "## X\n",
    "#list all X files and devide in train OR test folder\n",
    "filenames_X_train = []\n",
    "filenames_X_test = []\n",
    "directory_list = os.listdir(path_data_X)\n",
    "# print(directory_list)\n",
    "\n",
    "#random order list with filenames\n",
    "random.shuffle(directory_list)\n",
    "\n",
    "i = 0\n",
    "for filename in directory_list:\n",
    "    #print (filename) #all files, folders\n",
    "    #print (i)\n",
    "    if \".png\" in filename:\n",
    "        #print (filename)\n",
    "        if i % 3 == 0: \n",
    "            #1/3th of data is test set, rest in train\n",
    "            #print(i)\n",
    "            filenames_X_test.append(path_data_X + filename)\n",
    "        else:\n",
    "            filenames_X_train.append(path_data_X + filename)\n",
    "        i = i + 1\n",
    "        \n",
    " #check ok? 70-30 devide train - test? ok     \n",
    "print(len(filenames_X_train))\n",
    "print(len(filenames_X_test))\n",
    "\n",
    "\n",
    "## load X data + Merge per train/test X's with Y to S1\n",
    "#keep only non unique values\n",
    "\n",
    "\n",
    "def load_X_if_matched_in_y(filenames_list, y):\n",
    "    all_images_as_array=[]\n",
    "    label=[]    \n",
    "    # match = 0\n",
    "    # no_match = 0\n",
    "    for filename in filenames_list:\n",
    "        #print(filename)\n",
    "        #filename = filenames_X_train[3]\n",
    "        filename_wopath = filename.split('Xarrays/')[1]\n",
    "        #filename_wopath = filename_wopath[:-4] #wo .png todo, see same x/y !!!\n",
    "        # print(filename_wopath)\n",
    "    \n",
    "        matching_y = y[y.png==filename_wopath]\n",
    "        if len(matching_y) == 1:\n",
    "            label.append(matching_y.iloc[0,2]) #1st elem contains string NF/FOUND\n",
    "            \n",
    "            #load figure correctly as array [[], [], []]]\n",
    "            img=Image.open(filename)\n",
    "            np_array = np.asarray(img)\n",
    "            l,b,c = np_array.shape    \n",
    "            np_array = np_array.reshape(l*b*c,)   \n",
    "            all_images_as_array.append(np_array)\n",
    "            # match = match + 1\n",
    "            \n",
    "        if len(matching_y) != 1:\n",
    "            # print(\"no or multiple match(es) in y found for: \" + filename)\n",
    "            # no_match = no_match + 1\n",
    "            continue\n",
    "\n",
    "    return np.array(all_images_as_array), np.array(label)\n",
    "    \n",
    "\n",
    "#if re.match(filename_wopath, y.Name[0]): #todo search in volled colom, ev niet via regress want wo .png moet volled zelfde\n",
    "        \n",
    "\n",
    "\n",
    "X_train,y_train = load_X_if_matched_in_y(filenames_X_train, y)\n",
    "X_test, y_test = load_X_if_matched_in_y(filenames_X_test, y)\n",
    "\n",
    "\n",
    "# print(X_train)\n",
    "# print(len(y_train))\n",
    "# print(X_test)\n",
    "# print(len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6da57",
   "metadata": {},
   "source": [
    "create models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da700498",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a271b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.io import imread, imshow\n",
    "from skimage import data, color, io, filters, morphology,transform, exposure, feature, util\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "#importeer Tensorflow namespaces\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#K.set_image_dim_ordering('tf')\n",
    "\n",
    "###### Voor Tensorflow-GPU ########\n",
    "\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35ec4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisatie\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c34ded31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc62bf77dd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Toon afbeelding\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "index = 6   \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "\n",
    "imshow(X_train[index].reshape((128,128)),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebf3f893",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_6 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 128, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-02b7b5bb08e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#-----------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#-----------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#-----------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#-----------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2685\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2686\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    237\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_6 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 128, 128)"
     ]
    }
   ],
   "source": [
    "# Neural network parameters\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "batch_size = 32 # \n",
    "epochs = 100 # \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "num_classes = 2\n",
    "img_rows, img_cols = 128, 128\n",
    "input_shape = (img_rows, img_cols,2)\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=input_shape)) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(0.3)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "model.add(BatchNormalization())\n",
    "#-----------------------------------------------\n",
    "model.add(Conv2D(32, (3, 3), activation='relu')) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(0.3)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "model.add(BatchNormalization())\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(50, activation='relu')) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(0.2)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trainen van het CNN\n",
    "history = model.fit(X_train, y_train,batch_size=batch_size, epochs=epochs,  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuray \n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# Loss \n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7428e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performantie op de test data\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print('\\n')\n",
    "print('accuracy score:', accuracy_score(y_test, y_pred) * 100) \n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
